{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('DataSet_EU_3k_5k.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "We will be using Channel 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_24_columns = ['Power_24', 'NLI_24', 'ASE_24', 'frequency_24', 'Total Distance(m)', 'No. Spans', 'GSNR_24']\n",
    "data = dataset[channel_24_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Power_24</th>\n",
       "      <th>NLI_24</th>\n",
       "      <th>ASE_24</th>\n",
       "      <th>frequency_24</th>\n",
       "      <th>Total Distance(m)</th>\n",
       "      <th>No. Spans</th>\n",
       "      <th>GSNR_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>4.842871e-08</td>\n",
       "      <td>4.864403e-08</td>\n",
       "      <td>192450000000000</td>\n",
       "      <td>690608.0</td>\n",
       "      <td>8</td>\n",
       "      <td>76.723141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.885630e-08</td>\n",
       "      <td>5.247437e-08</td>\n",
       "      <td>192450000000000</td>\n",
       "      <td>690608.0</td>\n",
       "      <td>8</td>\n",
       "      <td>79.514276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.411925e-06</td>\n",
       "      <td>192450000000000</td>\n",
       "      <td>690608.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.423609e-06</td>\n",
       "      <td>192450000000000</td>\n",
       "      <td>690608.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.187909e-06</td>\n",
       "      <td>192450000000000</td>\n",
       "      <td>690608.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Power_24        NLI_24        ASE_24     frequency_24  Total Distance(m)  \\\n",
       "0  0.000007  4.842871e-08  4.864403e-08  192450000000000           690608.0   \n",
       "1  0.000007  3.885630e-08  5.247437e-08  192450000000000           690608.0   \n",
       "2  0.000000  0.000000e+00  7.411925e-06  192450000000000           690608.0   \n",
       "3  0.000000  0.000000e+00  7.423609e-06  192450000000000           690608.0   \n",
       "4  0.000000  0.000000e+00  7.187909e-06  192450000000000           690608.0   \n",
       "\n",
       "   No. Spans    GSNR_24  \n",
       "0          8  76.723141  \n",
       "1          8  79.514276  \n",
       "2          8   0.000000  \n",
       "3          8   0.000000  \n",
       "4          8   0.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the data types of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_24             float64\n",
       "NLI_24               float64\n",
       "ASE_24               float64\n",
       "frequency_24           int64\n",
       "Total Distance(m)    float64\n",
       "No. Spans              int64\n",
       "GSNR_24              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Power_24</th>\n",
       "      <th>NLI_24</th>\n",
       "      <th>ASE_24</th>\n",
       "      <th>frequency_24</th>\n",
       "      <th>Total Distance(m)</th>\n",
       "      <th>No. Spans</th>\n",
       "      <th>GSNR_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18000.000000</td>\n",
       "      <td>1.800000e+04</td>\n",
       "      <td>1.800000e+04</td>\n",
       "      <td>1.800000e+04</td>\n",
       "      <td>1.800000e+04</td>\n",
       "      <td>18000.00000</td>\n",
       "      <td>18000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>6.083256e-07</td>\n",
       "      <td>3.177172e-05</td>\n",
       "      <td>1.924500e+14</td>\n",
       "      <td>1.970755e+06</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>15.672157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>1.071328e-06</td>\n",
       "      <td>4.231358e-05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.023753e+06</td>\n",
       "      <td>11.41668</td>\n",
       "      <td>23.902547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.796777e-08</td>\n",
       "      <td>1.924500e+14</td>\n",
       "      <td>6.692970e+05</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.249564e-06</td>\n",
       "      <td>1.924500e+14</td>\n",
       "      <td>6.906080e+05</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.406459e-06</td>\n",
       "      <td>1.924500e+14</td>\n",
       "      <td>2.167932e+06</td>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>3.221394e-07</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1.924500e+14</td>\n",
       "      <td>3.051078e+06</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>17.120952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>3.670818e-06</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1.924500e+14</td>\n",
       "      <td>3.077685e+06</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>91.353745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Power_24        NLI_24        ASE_24  frequency_24  \\\n",
       "count  18000.000000  1.800000e+04  1.800000e+04  1.800000e+04   \n",
       "mean       0.000024  6.083256e-07  3.177172e-05  1.924500e+14   \n",
       "std        0.000038  1.071328e-06  4.231358e-05  0.000000e+00   \n",
       "min        0.000000  0.000000e+00  3.796777e-08  1.924500e+14   \n",
       "25%        0.000000  0.000000e+00  3.249564e-06  1.924500e+14   \n",
       "50%        0.000000  0.000000e+00  7.406459e-06  1.924500e+14   \n",
       "75%        0.000019  3.221394e-07  1.000000e-04  1.924500e+14   \n",
       "max        0.000095  3.670818e-06  1.000000e-04  1.924500e+14   \n",
       "\n",
       "       Total Distance(m)    No. Spans       GSNR_24  \n",
       "count       1.800000e+04  18000.00000  18000.000000  \n",
       "mean        1.970755e+06     22.00000     15.672157  \n",
       "std         1.023753e+06     11.41668     23.902547  \n",
       "min         6.692970e+05      7.00000      0.000000  \n",
       "25%         6.906080e+05      8.00000      0.000000  \n",
       "50%         2.167932e+06     24.50000      0.000000  \n",
       "75%         3.051078e+06     34.00000     17.120952  \n",
       "max         3.077685e+06     34.00000     91.353745  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_24             0\n",
       "NLI_24               0\n",
       "ASE_24               0\n",
       "frequency_24         0\n",
       "Total Distance(m)    0\n",
       "No. Spans            0\n",
       "GSNR_24              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data.iloc[:, :-1].values, data.iloc[:, -1].values, color = 'red')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Target Variable')\n",
    "plt.title('Features vs Target Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see from the plot that our data is non-linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size = (18000, 6)\n",
      "y size = (18000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X size = {X.shape}\\ny size = {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (14400, 6), (14400,)\n",
      "Validation set shape: (1800, 6), (1800,)\n",
      "Test set shape: (1800, 6), (1800,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "# X_scaled = sc.fit_transform(X)\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_val_scaled = sc.transform(X_val)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[0] = [7.33494511e-06 5.39951760e-08 4.64896996e-08 1.92450000e+14\n",
      " 6.90608000e+05 8.00000000e+00]\n",
      "X_train_scaled[0] = [-0.43357926 -0.51600236 -0.74863056  0.         -1.24578461 -1.22149915]\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train[0] = {X_train[0]}\\nX_train_scaled[0] = {X_train_scaled[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val[0] = [0.00000000e+00 0.00000000e+00 1.11321821e-05 1.92450000e+14\n",
      " 6.69297000e+05 7.00000000e+00]\n",
      "X_val_scaled[0] = [-0.62644825 -0.5664848  -0.48650759  0.         -1.26658322 -1.30901084]\n"
     ]
    }
   ],
   "source": [
    "print(f'X_val[0] = {X_val[0]}\\nX_val_scaled[0] = {X_val_scaled[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test[0] = [0.000000e+00 0.000000e+00 1.000000e-04 1.924500e+14 2.660552e+06\n",
      " 3.000000e+01]\n",
      "X_test_scaled[0] = [-0.62644825 -0.5664848   1.61478613  0.          0.67679573  0.7037581 ]\n"
     ]
    }
   ],
   "source": [
    "print(f'X_test[0] = {X_test[0]}\\nX_test_scaled[0] = {X_test_scaled[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu', name='input_layer'))\n",
    "    model.add(Dense(32, activation='relu', name='hidden_layer'))\n",
    "    model.add(Dense(1, activation='linear', name='output_layer')) \n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae']) # default learning rate for optimizer (adam) = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 64)                448       \n",
      "                                                                 \n",
      " hidden_layer (Dense)        (None, 32)                2080      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2561 (10.00 KB)\n",
      "Trainable params: 2561 (10.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "450/450 [==============================] - 3s 3ms/step - loss: 414.1324 - mae: 12.1101 - val_loss: 198.4825 - val_mae: 8.6113\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 102.1171 - mae: 6.2196 - val_loss: 32.9811 - val_mae: 3.3571\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 20.4123 - mae: 2.5017 - val_loss: 14.3908 - val_mae: 1.9104\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 13.2946 - mae: 1.8823 - val_loss: 11.3786 - val_mae: 1.6807\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 11.3493 - mae: 1.7231 - val_loss: 10.3341 - val_mae: 1.6783\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 10.1436 - mae: 1.5933 - val_loss: 8.6544 - val_mae: 1.3846\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 8.9175 - mae: 1.4405 - val_loss: 8.3367 - val_mae: 1.3568\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 7.7578 - mae: 1.2821 - val_loss: 6.5555 - val_mae: 1.1103\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 6.7032 - mae: 1.1564 - val_loss: 6.0122 - val_mae: 1.0021\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.8189 - mae: 1.0388 - val_loss: 5.2151 - val_mae: 0.8918\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 5.1421 - mae: 0.9585 - val_loss: 4.3451 - val_mae: 0.8072\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 4.4798 - mae: 0.8869 - val_loss: 4.1495 - val_mae: 0.9552\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 4.0405 - mae: 0.8419 - val_loss: 3.6692 - val_mae: 0.7346\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.7586 - mae: 0.8039 - val_loss: 3.9403 - val_mae: 0.7585\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 3.6137 - mae: 0.7967 - val_loss: 3.4740 - val_mae: 0.7225\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.5300 - mae: 0.7716 - val_loss: 3.5454 - val_mae: 0.8096\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 3.4399 - mae: 0.7653 - val_loss: 3.4161 - val_mae: 0.7608\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.4225 - mae: 0.7642 - val_loss: 3.3255 - val_mae: 0.7464\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.4179 - mae: 0.7598 - val_loss: 4.1928 - val_mae: 0.7933\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.4293 - mae: 0.7600 - val_loss: 3.7956 - val_mae: 0.8497\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.3999 - mae: 0.7633 - val_loss: 3.3066 - val_mae: 0.8025\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.4227 - mae: 0.7621 - val_loss: 3.5654 - val_mae: 0.8259\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.3669 - mae: 0.7492 - val_loss: 4.0420 - val_mae: 0.7919\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.3508 - mae: 0.7537 - val_loss: 3.4646 - val_mae: 0.7395\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.2639 - mae: 0.7483 - val_loss: 3.4773 - val_mae: 0.7113\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 3.2662 - mae: 0.7343 - val_loss: 3.3456 - val_mae: 0.6956\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 3.2974 - mae: 0.7381 - val_loss: 3.8740 - val_mae: 0.7904\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.2549 - mae: 0.7349 - val_loss: 3.3122 - val_mae: 0.6723\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 3.1945 - mae: 0.7189 - val_loss: 3.3019 - val_mae: 0.7084\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.3065 - mae: 0.7452 - val_loss: 3.2937 - val_mae: 0.7131\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.2168 - mae: 0.7345 - val_loss: 3.1831 - val_mae: 0.6613\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.1650 - mae: 0.7067 - val_loss: 3.2150 - val_mae: 0.7054\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.2004 - mae: 0.7207 - val_loss: 3.1667 - val_mae: 0.7255\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.2143 - mae: 0.7193 - val_loss: 3.0995 - val_mae: 0.6753\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.1634 - mae: 0.7218 - val_loss: 4.0905 - val_mae: 0.8241\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.1910 - mae: 0.7344 - val_loss: 3.0688 - val_mae: 0.6482\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.1799 - mae: 0.7168 - val_loss: 3.0244 - val_mae: 0.6450\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.2100 - mae: 0.7378 - val_loss: 3.9942 - val_mae: 0.7901\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.1677 - mae: 0.7329 - val_loss: 3.2129 - val_mae: 0.6724\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.1397 - mae: 0.7195 - val_loss: 3.0083 - val_mae: 0.6896\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.0795 - mae: 0.6876 - val_loss: 2.9912 - val_mae: 0.6798\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.0493 - mae: 0.7007 - val_loss: 4.0925 - val_mae: 0.7447\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.1053 - mae: 0.7146 - val_loss: 3.1080 - val_mae: 0.6967\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.0559 - mae: 0.7173 - val_loss: 3.0194 - val_mae: 0.6864\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.0145 - mae: 0.7032 - val_loss: 2.9002 - val_mae: 0.6489\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.0863 - mae: 0.7280 - val_loss: 3.2741 - val_mae: 0.9118\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.0126 - mae: 0.6972 - val_loss: 2.9130 - val_mae: 0.6286\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.9786 - mae: 0.6887 - val_loss: 3.7310 - val_mae: 0.7738\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.0234 - mae: 0.7086 - val_loss: 2.8857 - val_mae: 0.6580\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.0260 - mae: 0.7064 - val_loss: 2.9402 - val_mae: 0.6552\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.0270 - mae: 0.7069 - val_loss: 3.0994 - val_mae: 0.7366\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.9237 - mae: 0.6885 - val_loss: 2.8867 - val_mae: 0.6689\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.8899 - mae: 0.6821 - val_loss: 2.8484 - val_mae: 0.6312\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.9112 - mae: 0.6823 - val_loss: 2.7924 - val_mae: 0.6341\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 2.9624 - mae: 0.6960 - val_loss: 2.8310 - val_mae: 0.6323\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.8844 - mae: 0.6910 - val_loss: 2.7982 - val_mae: 0.6705\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.9653 - mae: 0.7035 - val_loss: 2.8619 - val_mae: 0.6602\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.9003 - mae: 0.6929 - val_loss: 2.8907 - val_mae: 0.7180\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.8626 - mae: 0.6662 - val_loss: 2.7792 - val_mae: 0.6466\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.8850 - mae: 0.6798 - val_loss: 3.0994 - val_mae: 0.6701\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.8910 - mae: 0.6887 - val_loss: 3.2450 - val_mae: 0.7665\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.8725 - mae: 0.6785 - val_loss: 2.8446 - val_mae: 0.7330\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.8127 - mae: 0.6814 - val_loss: 2.7110 - val_mae: 0.6422\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.8708 - mae: 0.6838 - val_loss: 2.9435 - val_mae: 0.6600\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.8487 - mae: 0.6753 - val_loss: 2.6914 - val_mae: 0.6694\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.8310 - mae: 0.6678 - val_loss: 2.6806 - val_mae: 0.6196\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.8012 - mae: 0.6816 - val_loss: 3.4431 - val_mae: 0.7030\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.8681 - mae: 0.6855 - val_loss: 2.6273 - val_mae: 0.6235\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.7751 - mae: 0.6750 - val_loss: 2.6027 - val_mae: 0.6002\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.7673 - mae: 0.6723 - val_loss: 2.6537 - val_mae: 0.7086\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 2.8524 - mae: 0.6838 - val_loss: 2.8137 - val_mae: 0.6751\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.7740 - mae: 0.6869 - val_loss: 2.5551 - val_mae: 0.5913\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.7852 - mae: 0.6637 - val_loss: 2.8007 - val_mae: 0.5814\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.7172 - mae: 0.6649 - val_loss: 2.5974 - val_mae: 0.6557\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 2.7587 - mae: 0.6753 - val_loss: 2.8068 - val_mae: 0.6571\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 2.7452 - mae: 0.6658 - val_loss: 2.8471 - val_mae: 0.7285\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.7073 - mae: 0.6777 - val_loss: 2.9771 - val_mae: 0.6978\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.6863 - mae: 0.6591 - val_loss: 4.9165 - val_mae: 0.9166\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.6730 - mae: 0.6576 - val_loss: 2.5027 - val_mae: 0.6319\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 2.8069 - mae: 0.6856 - val_loss: 2.6541 - val_mae: 0.6777\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.6400 - mae: 0.6486 - val_loss: 2.6286 - val_mae: 0.6183\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.6334 - mae: 0.6583 - val_loss: 2.4991 - val_mae: 0.5993\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.6232 - mae: 0.6726 - val_loss: 2.5845 - val_mae: 0.6746\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.5557 - mae: 0.6278 - val_loss: 2.4689 - val_mae: 0.6491\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 2.6220 - mae: 0.6600 - val_loss: 2.4468 - val_mae: 0.5676\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 2.6248 - mae: 0.6673 - val_loss: 2.6957 - val_mae: 0.5941\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 2.7555 - mae: 0.6784 - val_loss: 2.4978 - val_mae: 0.5660\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 2.5945 - mae: 0.6540 - val_loss: 2.4090 - val_mae: 0.6360\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.6245 - mae: 0.6563 - val_loss: 2.6400 - val_mae: 0.5660\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.6285 - mae: 0.6620 - val_loss: 2.4310 - val_mae: 0.5763\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.5579 - mae: 0.6334 - val_loss: 3.1875 - val_mae: 0.6874\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 2.5388 - mae: 0.6495 - val_loss: 2.5670 - val_mae: 0.6824\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 2.5450 - mae: 0.6447 - val_loss: 2.3914 - val_mae: 0.6503\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.5892 - mae: 0.6563 - val_loss: 2.9511 - val_mae: 0.6726\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.5101 - mae: 0.6411 - val_loss: 2.5105 - val_mae: 0.6189\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 2.5105 - mae: 0.6480 - val_loss: 2.8892 - val_mae: 0.6349\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.4471 - mae: 0.6235 - val_loss: 2.3215 - val_mae: 0.5470\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.4803 - mae: 0.6464 - val_loss: 2.4565 - val_mae: 0.5518\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.4614 - mae: 0.6268 - val_loss: 2.2958 - val_mae: 0.5472\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 2.4796 - mae: 0.6317 - val_loss: 2.8980 - val_mae: 0.5925\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, validation_data=(X_val_scaled, y_val), batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 2.8787 - mae: 0.6171\n",
      "Test Loss: 2.879\n",
      "Test MAE: 0.617\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Loss: {test_loss:.3f}')\n",
    "print(f'Test MAE: {test_mae:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "data = dataset[channel_24_columns]  # since we are using channel 24 as target variable\n",
    "X = data.drop('GSNR_24', axis=1).values\n",
    "y = data['GSNR_24'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 6)\n",
      "(3600, 6)\n",
      "(1800, 6)\n",
      "(1800, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_temp.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further split the training set into initial training and pool sets\n",
    "X_initial, X_pool, y_initial, y_pool = train_test_split(X_train, y_train, test_size=0.95, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 6)\n",
      "(13680, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_initial.shape)\n",
    "print(X_pool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_initial.shape[1], activation='relu', name='input_layer'))\n",
    "    model.add(Dense(32, activation='relu', name='hidden_layer'))\n",
    "    model.add(Dense(1, activation='linear', name='output_layer'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "model = build_model()\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 3s 21ms/step - loss: 822.8286 - mae: 15.9881 - val_loss: 748.1387 - val_mae: 14.7343\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 783.6758 - mae: 15.6370 - val_loss: 703.2844 - val_mae: 14.3038\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 727.3784 - mae: 15.0518 - val_loss: 638.5070 - val_mae: 13.5903\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 647.6884 - mae: 14.2264 - val_loss: 558.9932 - val_mae: 12.7121\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 559.5112 - mae: 13.5042 - val_loss: 477.3636 - val_mae: 12.5152\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 477.3105 - mae: 13.4651 - val_loss: 415.7982 - val_mae: 12.6660\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 421.1394 - mae: 13.4099 - val_loss: 379.2833 - val_mae: 12.5915\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 390.4430 - mae: 13.1443 - val_loss: 358.8012 - val_mae: 12.2732\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 370.0459 - mae: 12.6833 - val_loss: 341.1161 - val_mae: 11.8067\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 352.8669 - mae: 12.1929 - val_loss: 324.0723 - val_mae: 11.3114\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 332.7649 - mae: 11.7083 - val_loss: 305.7925 - val_mae: 10.8803\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 314.0003 - mae: 11.1069 - val_loss: 288.3637 - val_mae: 10.3414\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 295.1310 - mae: 10.6319 - val_loss: 272.0941 - val_mae: 9.8534\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 277.2694 - mae: 10.0955 - val_loss: 255.1118 - val_mae: 9.4988\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 259.9417 - mae: 9.7509 - val_loss: 238.5877 - val_mae: 9.1939\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 243.1907 - mae: 9.4447 - val_loss: 222.3295 - val_mae: 8.9101\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 225.8299 - mae: 9.2065 - val_loss: 206.6368 - val_mae: 8.6412\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 208.7839 - mae: 8.8746 - val_loss: 190.7965 - val_mae: 8.3027\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 192.9957 - mae: 8.5943 - val_loss: 174.9670 - val_mae: 8.0367\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 177.2429 - mae: 8.3064 - val_loss: 160.7112 - val_mae: 7.7527\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 163.0482 - mae: 8.0662 - val_loss: 146.1413 - val_mae: 7.5387\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 147.3094 - mae: 7.7718 - val_loss: 133.6680 - val_mae: 7.2756\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 138.8382 - mae: 7.5592 - val_loss: 121.8951 - val_mae: 6.9699\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 122.6063 - mae: 7.2203 - val_loss: 110.1313 - val_mae: 6.7279\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 111.3989 - mae: 6.8544 - val_loss: 99.4745 - val_mae: 6.4080\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 100.6463 - mae: 6.5599 - val_loss: 88.7450 - val_mae: 6.0218\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 88.8081 - mae: 6.0665 - val_loss: 80.3360 - val_mae: 5.6866\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 80.7347 - mae: 5.8090 - val_loss: 71.3596 - val_mae: 5.3178\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 71.7557 - mae: 5.3395 - val_loss: 64.2850 - val_mae: 5.0521\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 63.9950 - mae: 5.1190 - val_loss: 57.9361 - val_mae: 4.5407\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 59.3421 - mae: 4.7196 - val_loss: 50.0387 - val_mae: 4.3243\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 50.0114 - mae: 4.3294 - val_loss: 44.8121 - val_mae: 4.1201\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 45.4725 - mae: 4.1564 - val_loss: 40.6650 - val_mae: 3.8457\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 40.9853 - mae: 3.9938 - val_loss: 37.1811 - val_mae: 3.6099\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 38.3337 - mae: 3.7820 - val_loss: 33.6363 - val_mae: 3.5975\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 34.4943 - mae: 3.5777 - val_loss: 30.9279 - val_mae: 3.4542\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 31.3148 - mae: 3.4805 - val_loss: 28.0541 - val_mae: 3.1828\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 29.0121 - mae: 3.2749 - val_loss: 26.1691 - val_mae: 3.0197\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 26.6443 - mae: 3.1948 - val_loss: 23.7173 - val_mae: 2.9249\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 24.1299 - mae: 3.0069 - val_loss: 21.9267 - val_mae: 2.8709\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 22.5135 - mae: 2.8823 - val_loss: 20.3270 - val_mae: 2.7191\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 21.0983 - mae: 2.7668 - val_loss: 19.3756 - val_mae: 2.7091\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 19.8310 - mae: 2.7247 - val_loss: 17.8889 - val_mae: 2.5461\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 19.0192 - mae: 2.7117 - val_loss: 17.1898 - val_mae: 2.4973\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 18.1125 - mae: 2.6399 - val_loss: 16.3780 - val_mae: 2.4500\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 17.3879 - mae: 2.5707 - val_loss: 16.3426 - val_mae: 2.3678\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 17.1737 - mae: 2.5655 - val_loss: 15.1081 - val_mae: 2.3575\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 16.3820 - mae: 2.5247 - val_loss: 14.6956 - val_mae: 2.2451\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 15.7033 - mae: 2.4474 - val_loss: 14.1413 - val_mae: 2.2110\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 15.2834 - mae: 2.3721 - val_loss: 14.0080 - val_mae: 2.1812\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 15.1859 - mae: 2.3608 - val_loss: 13.6605 - val_mae: 2.1636\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 14.9697 - mae: 2.3408 - val_loss: 13.2602 - val_mae: 2.1175\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 14.4875 - mae: 2.2684 - val_loss: 12.9338 - val_mae: 2.0855\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 14.3950 - mae: 2.2463 - val_loss: 12.7213 - val_mae: 2.0097\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 14.4178 - mae: 2.1858 - val_loss: 12.8669 - val_mae: 2.0398\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 14.3540 - mae: 2.2144 - val_loss: 12.4073 - val_mae: 2.0162\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 14.1602 - mae: 2.1423 - val_loss: 12.5143 - val_mae: 2.0534\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 13.6164 - mae: 2.1049 - val_loss: 12.1442 - val_mae: 1.8955\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 13.5680 - mae: 2.0769 - val_loss: 11.9319 - val_mae: 1.9002\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 13.2098 - mae: 2.0380 - val_loss: 12.1222 - val_mae: 1.8264\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 13.2949 - mae: 2.0199 - val_loss: 11.6920 - val_mae: 1.8038\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 13.1247 - mae: 2.0003 - val_loss: 11.6188 - val_mae: 1.7805\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 13.1065 - mae: 1.9647 - val_loss: 11.3787 - val_mae: 1.7378\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 12.9270 - mae: 1.9513 - val_loss: 11.2105 - val_mae: 1.7411\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 12.7726 - mae: 1.9839 - val_loss: 11.4481 - val_mae: 1.7280\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 12.8267 - mae: 1.9095 - val_loss: 11.3133 - val_mae: 1.7088\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 12.8342 - mae: 1.9346 - val_loss: 10.9332 - val_mae: 1.6707\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 12.2556 - mae: 1.8742 - val_loss: 10.7263 - val_mae: 1.6560\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 12.1016 - mae: 1.8190 - val_loss: 10.6850 - val_mae: 1.6351\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 12.0544 - mae: 1.8252 - val_loss: 10.6443 - val_mae: 1.6223\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 11.9681 - mae: 1.8161 - val_loss: 10.4378 - val_mae: 1.5861\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 11.7588 - mae: 1.7731 - val_loss: 10.4127 - val_mae: 1.5849\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 11.6402 - mae: 1.7774 - val_loss: 10.2570 - val_mae: 1.5695\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 11.7215 - mae: 1.7654 - val_loss: 10.2162 - val_mae: 1.5343\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 11.4566 - mae: 1.7451 - val_loss: 10.1905 - val_mae: 1.5432\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 11.9079 - mae: 1.7571 - val_loss: 10.3135 - val_mae: 1.6216\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 11.6607 - mae: 1.7350 - val_loss: 10.2389 - val_mae: 1.5108\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 11.4016 - mae: 1.7282 - val_loss: 9.7968 - val_mae: 1.5232\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 11.2331 - mae: 1.6988 - val_loss: 9.8834 - val_mae: 1.5330\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 11.1274 - mae: 1.6845 - val_loss: 9.6841 - val_mae: 1.4624\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 10.9868 - mae: 1.6612 - val_loss: 9.6273 - val_mae: 1.4610\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 11.0691 - mae: 1.6572 - val_loss: 9.9370 - val_mae: 1.4948\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 10.9585 - mae: 1.6812 - val_loss: 9.8129 - val_mae: 1.4568\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 10.7365 - mae: 1.6368 - val_loss: 9.3935 - val_mae: 1.4439\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 10.6613 - mae: 1.6352 - val_loss: 9.3291 - val_mae: 1.4812\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 10.5586 - mae: 1.6165 - val_loss: 9.3253 - val_mae: 1.4293\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 10.7892 - mae: 1.6227 - val_loss: 9.3627 - val_mae: 1.4381\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 10.6960 - mae: 1.6568 - val_loss: 9.5891 - val_mae: 1.4666\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 10.4314 - mae: 1.6059 - val_loss: 9.0342 - val_mae: 1.4281\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 10.1925 - mae: 1.5740 - val_loss: 8.9446 - val_mae: 1.3872\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 10.2568 - mae: 1.5726 - val_loss: 8.9829 - val_mae: 1.4132\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 10.2221 - mae: 1.5695 - val_loss: 8.9641 - val_mae: 1.3690\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 10.1552 - mae: 1.5740 - val_loss: 9.2167 - val_mae: 1.3924\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 10.6929 - mae: 1.5942 - val_loss: 8.6874 - val_mae: 1.3710\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 9.8509 - mae: 1.5415 - val_loss: 8.6139 - val_mae: 1.3547\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 9.8606 - mae: 1.5328 - val_loss: 8.8243 - val_mae: 1.3617\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 9.6676 - mae: 1.5181 - val_loss: 8.5704 - val_mae: 1.3385\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 9.6598 - mae: 1.5146 - val_loss: 8.4751 - val_mae: 1.3474\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 9.7013 - mae: 1.5167 - val_loss: 8.5013 - val_mae: 1.3679\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 9.5546 - mae: 1.5316 - val_loss: 8.3236 - val_mae: 1.3535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1af75df6690>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the initial model\n",
    "model.fit(X_initial, y_initial, validation_data=(X_val, y_val), batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 8.9763 - mae: 1.4494\n",
      "Test Loss: 8.976\n",
      "Test MAE: 1.449\n"
     ]
    }
   ],
   "source": [
    "# Evaluate initial model\n",
    "test_loss_al, test_mae_al = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Loss: {test_loss_al:.3f}')\n",
    "print(f'Test MAE: {test_mae_al:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10\n",
    "samples_per_iteration = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/428 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 36.3024 - mae: 3.3549 - val_loss: 12.7588 - val_mae: 1.7614\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 34.7620 - mae: 3.2682 - val_loss: 13.5356 - val_mae: 1.8643\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 34.3373 - mae: 3.2475 - val_loss: 10.8036 - val_mae: 1.6370\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 32.3850 - mae: 3.0811 - val_loss: 13.7364 - val_mae: 1.8079\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 31.8848 - mae: 3.0612 - val_loss: 15.7579 - val_mae: 1.9653\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 32.0837 - mae: 3.0551 - val_loss: 13.0063 - val_mae: 1.7493\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 31.1354 - mae: 3.0455 - val_loss: 15.3884 - val_mae: 1.9155\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 30.6573 - mae: 2.9954 - val_loss: 11.0666 - val_mae: 1.6161\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 29.8240 - mae: 2.9597 - val_loss: 12.7321 - val_mae: 1.7487\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 29.6995 - mae: 2.9573 - val_loss: 11.1494 - val_mae: 1.6253\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 11.1494 - mae: 1.6253\n",
      "Iteration 1/10 - Validation Loss: 11.149, Validation MAE: 1.625\n",
      "425/425 [==============================] - 1s 3ms/step\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 46.7534 - mae: 4.1618 - val_loss: 7.4887 - val_mae: 1.4720\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 44.6666 - mae: 4.0532 - val_loss: 7.4992 - val_mae: 1.4496\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 43.2375 - mae: 3.9973 - val_loss: 7.9625 - val_mae: 1.5239\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 42.0918 - mae: 3.9462 - val_loss: 7.2672 - val_mae: 1.3988\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 41.3178 - mae: 3.8975 - val_loss: 6.6953 - val_mae: 1.3808\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 40.3367 - mae: 3.8707 - val_loss: 6.7102 - val_mae: 1.3768\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 39.1166 - mae: 3.8024 - val_loss: 6.6808 - val_mae: 1.3824\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 37.4907 - mae: 3.7524 - val_loss: 6.0738 - val_mae: 1.3298\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 36.1506 - mae: 3.6775 - val_loss: 6.8984 - val_mae: 1.4971\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 36.2291 - mae: 3.7079 - val_loss: 6.0063 - val_mae: 1.3444\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 6.0063 - mae: 1.3444\n",
      "Iteration 2/10 - Validation Loss: 6.006, Validation MAE: 1.344\n",
      "422/422 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 39.4443 - mae: 4.1509 - val_loss: 5.9552 - val_mae: 1.3881\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 38.3655 - mae: 4.1320 - val_loss: 6.2231 - val_mae: 1.4913\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 37.7568 - mae: 4.0420 - val_loss: 6.5613 - val_mae: 1.5519\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 35.8615 - mae: 3.9708 - val_loss: 5.3933 - val_mae: 1.3762\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 34.7580 - mae: 3.9191 - val_loss: 5.3967 - val_mae: 1.3562\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 33.2142 - mae: 3.8389 - val_loss: 5.2652 - val_mae: 1.3620\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 31.9892 - mae: 3.7725 - val_loss: 5.4717 - val_mae: 1.2999\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 31.3677 - mae: 3.6991 - val_loss: 5.1665 - val_mae: 1.3308\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 30.2653 - mae: 3.6854 - val_loss: 5.9232 - val_mae: 1.4194\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 28.8770 - mae: 3.5824 - val_loss: 4.7835 - val_mae: 1.2793\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.7835 - mae: 1.2793\n",
      "Iteration 3/10 - Validation Loss: 4.783, Validation MAE: 1.279\n",
      "419/419 [==============================] - 1s 3ms/step\n",
      "Epoch 1/10\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 32.9108 - mae: 3.9670 - val_loss: 5.7217 - val_mae: 1.5196\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 30.3243 - mae: 3.8796 - val_loss: 4.5429 - val_mae: 1.2694\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 29.2935 - mae: 3.7759 - val_loss: 4.7608 - val_mae: 1.2458\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 28.5964 - mae: 3.7239 - val_loss: 4.6430 - val_mae: 1.2170\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 27.8737 - mae: 3.6657 - val_loss: 4.3503 - val_mae: 1.1786\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.9405 - mae: 3.6141 - val_loss: 4.4576 - val_mae: 1.2077\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.3899 - mae: 3.5907 - val_loss: 4.7611 - val_mae: 1.2852\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 27.6141 - mae: 3.6580 - val_loss: 4.1932 - val_mae: 1.1334\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 25.6866 - mae: 3.4518 - val_loss: 4.0793 - val_mae: 1.0743\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 25.5708 - mae: 3.4205 - val_loss: 3.9908 - val_mae: 1.1262\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.9908 - mae: 1.1262\n",
      "Iteration 4/10 - Validation Loss: 3.991, Validation MAE: 1.126\n",
      "415/415 [==============================] - 1s 3ms/step\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 27.0558 - mae: 3.6512 - val_loss: 4.1398 - val_mae: 1.1087\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 27.5912 - mae: 3.6478 - val_loss: 4.1172 - val_mae: 1.1844\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 26.9890 - mae: 3.6125 - val_loss: 3.8855 - val_mae: 1.0926\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 26.7047 - mae: 3.5737 - val_loss: 3.6922 - val_mae: 1.0036\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 26.4395 - mae: 3.5431 - val_loss: 3.6898 - val_mae: 0.9629\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 26.4525 - mae: 3.5260 - val_loss: 4.4303 - val_mae: 1.0878\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 27.0029 - mae: 3.5811 - val_loss: 3.6755 - val_mae: 0.9317\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 26.4449 - mae: 3.5212 - val_loss: 3.6083 - val_mae: 0.9087\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 26.3464 - mae: 3.4572 - val_loss: 3.9295 - val_mae: 1.0679\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 26.1101 - mae: 3.5151 - val_loss: 4.0162 - val_mae: 1.1268\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.0162 - mae: 1.1268\n",
      "Iteration 5/10 - Validation Loss: 4.016, Validation MAE: 1.127\n",
      "412/412 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 28.3867 - mae: 3.8375 - val_loss: 3.6033 - val_mae: 0.9612\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 27.1032 - mae: 3.7145 - val_loss: 4.2585 - val_mae: 1.2104\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 27.4166 - mae: 3.7924 - val_loss: 3.9001 - val_mae: 1.0635\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 27.3508 - mae: 3.7213 - val_loss: 4.2055 - val_mae: 1.0163\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 27.7528 - mae: 3.7218 - val_loss: 3.6807 - val_mae: 0.9175\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 27.1011 - mae: 3.7744 - val_loss: 4.0664 - val_mae: 1.1349\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 27.1161 - mae: 3.7274 - val_loss: 3.6359 - val_mae: 0.9530\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 27.4637 - mae: 3.7356 - val_loss: 3.6715 - val_mae: 0.9897\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 26.8757 - mae: 3.7149 - val_loss: 3.4772 - val_mae: 0.8477\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 26.6682 - mae: 3.6640 - val_loss: 3.9047 - val_mae: 1.0014\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.9047 - mae: 1.0014\n",
      "Iteration 6/10 - Validation Loss: 3.905, Validation MAE: 1.001\n",
      "409/409 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 25.7458 - mae: 3.6763 - val_loss: 3.6342 - val_mae: 0.8899\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 25.4234 - mae: 3.6059 - val_loss: 3.4361 - val_mae: 0.8600\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 25.6887 - mae: 3.6327 - val_loss: 4.7408 - val_mae: 1.2970\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 25.3871 - mae: 3.6519 - val_loss: 3.8168 - val_mae: 0.9549\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 25.7727 - mae: 3.6611 - val_loss: 3.3364 - val_mae: 0.8113\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 25.3958 - mae: 3.6012 - val_loss: 3.4795 - val_mae: 0.8794\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 25.1579 - mae: 3.6035 - val_loss: 3.4975 - val_mae: 0.9457\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 25.0927 - mae: 3.6308 - val_loss: 3.8222 - val_mae: 0.9375\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 24.9483 - mae: 3.5570 - val_loss: 3.4191 - val_mae: 0.8183\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 24.9974 - mae: 3.5623 - val_loss: 3.2836 - val_mae: 0.7639\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.2836 - mae: 0.7639\n",
      "Iteration 7/10 - Validation Loss: 3.284, Validation MAE: 0.764\n",
      "406/406 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 25.9204 - mae: 3.7856 - val_loss: 4.0139 - val_mae: 1.1546\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 25.4578 - mae: 3.7412 - val_loss: 3.8197 - val_mae: 0.9096\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 25.5011 - mae: 3.7966 - val_loss: 3.9929 - val_mae: 1.0786\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 26.4160 - mae: 3.8053 - val_loss: 4.2758 - val_mae: 1.3368\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 25.5862 - mae: 3.8025 - val_loss: 3.3789 - val_mae: 0.8805\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 25.0424 - mae: 3.7028 - val_loss: 3.2991 - val_mae: 0.8425\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 25.4191 - mae: 3.7117 - val_loss: 3.4051 - val_mae: 0.8045\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 25.4929 - mae: 3.7247 - val_loss: 3.5961 - val_mae: 1.0043\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 24.7294 - mae: 3.6777 - val_loss: 3.3640 - val_mae: 0.8515\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 25.2913 - mae: 3.7572 - val_loss: 4.6361 - val_mae: 1.3022\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.6361 - mae: 1.3022\n",
      "Iteration 8/10 - Validation Loss: 4.636, Validation MAE: 1.302\n",
      "403/403 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 23.9111 - mae: 3.6670 - val_loss: 3.2255 - val_mae: 0.8295\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 24.0132 - mae: 3.6302 - val_loss: 3.5482 - val_mae: 0.9203\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 24.4391 - mae: 3.6187 - val_loss: 3.2135 - val_mae: 0.7975\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 23.5129 - mae: 3.5713 - val_loss: 3.3635 - val_mae: 0.8421\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 23.7387 - mae: 3.5794 - val_loss: 3.3219 - val_mae: 0.9136\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 23.4032 - mae: 3.5657 - val_loss: 3.3410 - val_mae: 0.8220\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 23.4530 - mae: 3.5572 - val_loss: 3.3019 - val_mae: 0.8409\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 23.4021 - mae: 3.5665 - val_loss: 3.5073 - val_mae: 0.8410\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 24.1265 - mae: 3.6587 - val_loss: 3.3600 - val_mae: 0.9085\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 23.5240 - mae: 3.5767 - val_loss: 3.3512 - val_mae: 0.7534\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.3512 - mae: 0.7534\n",
      "Iteration 9/10 - Validation Loss: 3.351, Validation MAE: 0.753\n",
      "400/400 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 22.5524 - mae: 3.5050 - val_loss: 3.2019 - val_mae: 0.7798\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 22.8412 - mae: 3.5448 - val_loss: 3.6885 - val_mae: 1.0870\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 22.6053 - mae: 3.5050 - val_loss: 3.2463 - val_mae: 0.8193\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 21.9945 - mae: 3.4343 - val_loss: 3.1147 - val_mae: 0.7440\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 22.2709 - mae: 3.4599 - val_loss: 3.3722 - val_mae: 0.8794\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 22.2044 - mae: 3.4717 - val_loss: 3.0881 - val_mae: 0.7655\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 22.6214 - mae: 3.4949 - val_loss: 3.0914 - val_mae: 0.7901\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 22.1185 - mae: 3.4656 - val_loss: 4.0095 - val_mae: 0.9432\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 23.2355 - mae: 3.5502 - val_loss: 5.6404 - val_mae: 1.4739\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 23.1975 - mae: 3.5344 - val_loss: 4.2245 - val_mae: 1.2489\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 4.2245 - mae: 1.2489\n",
      "Iteration 10/10 - Validation Loss: 4.225, Validation MAE: 1.249\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(num_iterations):\n",
    "    # Predict on the pool set\n",
    "    y_pool_pred = model.predict(X_pool)\n",
    "    \n",
    "    # Calculate uncertainty (absolute error in this case)\n",
    "    uncertainties = np.abs(y_pool_pred.flatten() - y_pool)\n",
    "    \n",
    "    # Ensure uncertainties array is correctly handled\n",
    "    if len(uncertainties) != len(y_pool):\n",
    "        raise ValueError(\"Mismatch between uncertainties and pool set lengths.\")\n",
    "    \n",
    "    # Select the most uncertain samples\n",
    "    uncertain_samples_indices = np.argsort(-uncertainties)[:samples_per_iteration]\n",
    "    \n",
    "    # Ensure selected indices are within bounds\n",
    "    if np.max(uncertain_samples_indices) >= X_pool.shape[0]:\n",
    "        raise IndexError(\"Selected indices are out of bounds for the pool set.\")\n",
    "    \n",
    "    # Select the samples\n",
    "    X_selected = X_pool[uncertain_samples_indices]\n",
    "    y_selected = y_pool[uncertain_samples_indices]\n",
    "    \n",
    "    # Add selected samples to the training set\n",
    "    X_initial = np.vstack((X_initial, X_selected))\n",
    "    y_initial = np.concatenate((y_initial, y_selected))\n",
    "    \n",
    "    # Remove selected samples from the pool set\n",
    "    X_pool = np.delete(X_pool, uncertain_samples_indices, axis=0)\n",
    "    y_pool = np.delete(y_pool, uncertain_samples_indices, axis=0)\n",
    "    \n",
    "    # Retrain the model\n",
    "    model.fit(X_initial, y_initial, validation_data=(X_val, y_val), batch_size=32, epochs=10)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss, val_mae = model.evaluate(X_val, y_val)\n",
    "    print(f'Iteration {iteration+1}/{num_iterations} - Validation Loss: {val_loss:.3f}, Validation MAE: {val_mae:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mae: 0.0000e+00\n",
      "Final Test Loss: 0.000\n",
      "Final Test MAE: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on the test set\n",
    "test_loss, test_mae = model.evaluate(X_test)\n",
    "print(f'Final Test Loss: {test_loss:.3f}')\n",
    "print(f'Final Test MAE: {test_mae:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
